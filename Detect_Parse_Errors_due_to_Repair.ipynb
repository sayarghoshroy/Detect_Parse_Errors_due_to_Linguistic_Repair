{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Project\n",
    "# Detecting Errors in Parsing of Speech Transcript\n",
    "# Sandesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = {}\n",
    "\n",
    "for test_file in range(1, 5):\n",
    "    file = open('test_' + str(test_file) + '.txt', 'r')\n",
    "    file_string = file.read()\n",
    "    tokenized_sentences = file_string.split('\\n')\n",
    "    test_files[test_file] = tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_example_A = test_files[1][1]\n",
    "sentence_example_B = \"I would like to , I would want to go to the zoo .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the processor\n",
    "proc = spacy.load(\"en_core_web_sm\")\n",
    "embedder = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# if errors: do this, this is what worked for me\n",
    "# python -m spacy download en\n",
    "# conda install -c conda-forge spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy link en_core_web_sm en --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"88cb6fec107240378c240f13a095ad88-0\" class=\"displacy\" width=\"2150\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">would</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">to ,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">would</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">want</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">go</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">zoo .</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-88cb6fec107240378c240f13a095ad88-0-10\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-88cb6fec107240378c240f13a095ad88-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,266.5 L1978.0,254.5 1962.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "extract = proc(sentence_example_B)\n",
    "# uncomment the following line to see a version of the dependency graph\n",
    "displacy.serve(extract, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root(extract):\n",
    "    for token in extract:\n",
    "        if token.head == token:\n",
    "            return token\n",
    "        # root has been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_xcomp_violations(node):\n",
    "    all_children = [child for child in node.children]\n",
    "    \n",
    "    if len(all_children) == 0:\n",
    "        if node.dep_ == 'xcomp':\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    else:\n",
    "        subtree_result = True\n",
    "        for child in node.children:\n",
    "            subtree_result = subtree_result and check_xcomp_violations(child)\n",
    "            \n",
    "        return subtree_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_xcomp_conditions(extract, suppress = 0):\n",
    "    root_token = find_root(extract)\n",
    "    is_valid = check_xcomp_violations(root_token)\n",
    "    \n",
    "    if is_valid == True:\n",
    "        if suppress == 0:\n",
    "            print(\"No violations in xcomp clause structures found\")\n",
    "        return 1\n",
    "    else:\n",
    "        if suppress == 0:\n",
    "            print(\"xcomp clause structure violated.\")\n",
    "        return 0\n",
    "        \n",
    "    # returns code 1 for Green, 0 for Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(node):\n",
    "    all_children = [child for child in node.children]\n",
    "    \n",
    "    if len(all_children) == 0:\n",
    "        # encountered a leaf node\n",
    "        return 1\n",
    "    else:\n",
    "        subtree_size = 1  \n",
    "\n",
    "        for child in node.children:\n",
    "            subtree_size += get_size(child)\n",
    "            \n",
    "        return subtree_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_connected(extract, suppress = 0):\n",
    "    root_token = find_root(extract)\n",
    "    tree_size = get_size(root_token)\n",
    "    \n",
    "    if suppress == 0:\n",
    "        print(\"Number of Tokens: \", str(tree_size))\n",
    "    if tree_size == len(extract):\n",
    "        if suppress == 0:\n",
    "            print(\"The Parse yields a tree.\")\n",
    "        return 1\n",
    "    else:\n",
    "        if suppress == 0:\n",
    "            print(\"The parse does not yield a tree. Hence, this is an error.\")\n",
    "        return 0\n",
    "        \n",
    "    # returns code 1 for Green, 0 for Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_features(extract):\n",
    "    count = 0\n",
    "    index_arr = []\n",
    "    words = []\n",
    "    labels = []\n",
    "    parent_word = []\n",
    "    pos = []\n",
    "    count_children = []\n",
    "    \n",
    "    for token in extract:\n",
    "        count += 1\n",
    "        index_arr.append(str(count))\n",
    "        words.append(token.text)\n",
    "        labels.append(token.dep_)\n",
    "        parent_word.append(token.head.text)\n",
    "        pos.append(token.pos_.lower())\n",
    "        count_children.append(len([child for child in token.children]))\n",
    "        \n",
    "    d = {'Token Word': words, 'Dependency Label': labels, 'Parent Word': parent_word,\n",
    "         'POS': pos, 'Number of Children': count_children}\n",
    "    df = pd.DataFrame(index = index_arr, data = d)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetition Detection\n",
    "# Based on word-embeddings\n",
    "# Using embedder, loaded above\n",
    "all_structs = []\n",
    "\n",
    "def get_structs(node):\n",
    "    all_children = [child for child in node.children]\n",
    "    \n",
    "    if len(all_children) == 0:\n",
    "        # encountered a leaf node\n",
    "        embeddings = embedder(node.text)\n",
    "        create_struct = {'size': 1, 'hash': np.asarray(embeddings[0].vector), 'node': node} \n",
    "        all_structs.append(create_struct)\n",
    "        return create_struct\n",
    "    \n",
    "    else:\n",
    "        subtree_size = 1\n",
    "        embeddings = embedder(node.text)\n",
    "        subtree_hash = np.asarray(embeddings[0].vector)\n",
    "        \n",
    "        for child in node.children:\n",
    "            temp_struct = get_structs(child)\n",
    "            subtree_hash = subtree_hash + temp_struct['hash']\n",
    "            subtree_size += temp_struct['size']\n",
    "            \n",
    "        create_struct = {'size': subtree_size, 'hash': subtree_hash, 'node': node}\n",
    "        all_structs.append(create_struct)\n",
    "        return create_struct\n",
    "                \n",
    "def make_all_structs(extract):\n",
    "    global all_structs\n",
    "    all_structs = []\n",
    "    root = find_root(extract)\n",
    "    # create a dictionary that returns hash_value and size of subtrees rooted at each node\n",
    "    \n",
    "    root_struct = get_structs(root)\n",
    "    return root_struct\n",
    "\n",
    "def check_if_subtree(struct_A, struct_B):\n",
    "    if struct_A['size'] > struct_B['size']:\n",
    "        temp_struct = struct_A\n",
    "        struct_A = struct_B\n",
    "        struct_B = temp_struct\n",
    "        \n",
    "    token_big = struct_B['node']\n",
    "    token = struct_A['node']\n",
    "    \n",
    "    while token.head != token:\n",
    "        if token.head == token_big:\n",
    "            return True\n",
    "        token = token.head\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_lca(struct_A, struct_B):\n",
    "    path_to_A = []\n",
    "    path_to_B = []\n",
    "    \n",
    "    node_A = struct_A['node']\n",
    "    node_B = struct_B['node']\n",
    "    \n",
    "    while(node_A.head != node_A):\n",
    "        path_to_A.append(node_A)\n",
    "        node_A = node_A.head\n",
    "        \n",
    "    while(node_B.head != node_B):\n",
    "        path_to_B.append(node_B)\n",
    "        node_B = node_B.head\n",
    "        \n",
    "    path_to_A.reverse()\n",
    "    path_to_B.reverse()\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    while True:\n",
    "        if index >= len(path_to_A) or index >= len(path_to_B):\n",
    "            break\n",
    "        if path_to_A[index] != path_to_B[index]:\n",
    "            break\n",
    "        index += 1\n",
    "        \n",
    "    return index\n",
    "\n",
    "def get_height(struct):\n",
    "    node = struct['node']\n",
    "    height = 0\n",
    "    while(node.head != node):\n",
    "        height += 1\n",
    "        node = node.head\n",
    "    \n",
    "    return height\n",
    "\n",
    "def get_distance(struct_A, struct_B):\n",
    "    distance = get_height(struct_A) + get_height(struct_B) - 2 * get_lca(struct_A, struct_B)\n",
    "    return distance\n",
    "\n",
    "def similarity(vec_A, vec_B):\n",
    "    score_cos = np.dot(vec_A, vec_B) / (np.linalg.norm(vec_A) * np.linalg.norm(vec_B))\n",
    "    score_dist = np.linalg.norm(vec_A - vec_B)\n",
    "    return {'cosine': score_cos, 'dist': score_dist}\n",
    "\n",
    "def check_repetitions(suppress = 0):\n",
    "    global all_structs\n",
    "    count_A = 0\n",
    "    for struct_A in all_structs:\n",
    "        count_B = 0\n",
    "        for struct_B in all_structs:\n",
    "            if count_A == count_B:\n",
    "                continue\n",
    "            if (abs(count_A - count_B) <= 5) and get_distance(struct_A, struct_B) <= 7 and check_if_subtree(struct_A, struct_B) == False:\n",
    "                results = similarity((struct_A['hash'] / struct_A['size']), (struct_B['hash'] / struct_B['size']))\n",
    "                if results['cosine'] > 0.975 and results['dist'] < 1.15:\n",
    "                    return 1\n",
    "            count_B += 1\n",
    "        count_A += 1\n",
    "    return 0\n",
    "    # if repetition was found, return a 1\n",
    "    # else, return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetition Detection\n",
    "# Using N-sized window\n",
    "\n",
    "window_size = 7\n",
    "\n",
    "def check_repeat(extract, suppress = 0):\n",
    "    memory = []\n",
    "    repeats = 0\n",
    "    \n",
    "    for token in extract:\n",
    "        embeddings = embedder(token.text)\n",
    "        \n",
    "        is_fine = 1\n",
    "        for mem in memory:\n",
    "            score = similarity(np.asarray(embedder(mem.text).vector), np.asarray(embeddings[0].vector))\n",
    "            if score['cosine'] > 0.95 and (mem.pos_ == 'NOUN' or mem.pos_ == 'VERB' or token.pos_ == 'NOUN' or token.pos_ == 'VERB'):\n",
    "                is_fine = 0\n",
    "                break\n",
    "        \n",
    "        if is_fine == 0:\n",
    "            repeats = 1\n",
    "            break\n",
    "        \n",
    "        memory.append(token)\n",
    "        \n",
    "        while (len(memory) > window_size):\n",
    "            rem = memory.pop()\n",
    "    \n",
    "    if repeats == 1:\n",
    "        if suppress != 1:\n",
    "            print(\"Lexical Repetition Encountered\")\n",
    "        return 1\n",
    "    else:\n",
    "        if suppress != 1:\n",
    "            print(\"No Lexical Repetitons Encountered\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if a word-bigram has been uttered twice in atleast one window of 5 words\n",
    "def check_bi_repeat(extract, suppress = 0):\n",
    "    window = min(31, len(extract))\n",
    "    memory = []\n",
    "    for token in extract:\n",
    "        memory.append(token.text)\n",
    "        if(len(memory) < window):\n",
    "            continue\n",
    "        \n",
    "        while len(memory) > window:\n",
    "            rem = memory.pop()\n",
    "            \n",
    "        for init in range(2, window - 1):\n",
    "            if memory[0] == memory[init] and memory[1] == memory[init + 1]:\n",
    "                if suppress != 1:\n",
    "                    print(\"Bigram repeated\")\n",
    "                return 1\n",
    "    \n",
    "    if suppress != 1:\n",
    "        print(\"No bigram repetitions found\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens:  14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Word</th>\n",
       "      <th>Dependency Label</th>\n",
       "      <th>Parent Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Number of Children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>like</td>\n",
       "      <td>pron</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would</td>\n",
       "      <td>aux</td>\n",
       "      <td>like</td>\n",
       "      <td>aux</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>want</td>\n",
       "      <td>verb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>like</td>\n",
       "      <td>part</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>want</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>want</td>\n",
       "      <td>pron</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>would</td>\n",
       "      <td>aux</td>\n",
       "      <td>want</td>\n",
       "      <td>aux</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>want</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>want</td>\n",
       "      <td>verb</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>aux</td>\n",
       "      <td>go</td>\n",
       "      <td>part</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>go</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>want</td>\n",
       "      <td>verb</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>to</td>\n",
       "      <td>prep</td>\n",
       "      <td>go</td>\n",
       "      <td>adp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the</td>\n",
       "      <td>det</td>\n",
       "      <td>zoo</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>zoo</td>\n",
       "      <td>pobj</td>\n",
       "      <td>to</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>want</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token Word Dependency Label Parent Word    POS  Number of Children\n",
       "1           I            nsubj        like   pron                   0\n",
       "2       would              aux        like    aux                   0\n",
       "3        like            ccomp        want   verb                   3\n",
       "4          to            xcomp        like   part                   0\n",
       "5           ,            punct        want  punct                   0\n",
       "6           I            nsubj        want   pron                   0\n",
       "7       would              aux        want    aux                   0\n",
       "8        want             ROOT        want   verb                   6\n",
       "9          to              aux          go   part                   0\n",
       "10         go            xcomp        want   verb                   2\n",
       "11         to             prep          go    adp                   1\n",
       "12        the              det         zoo    det                   0\n",
       "13        zoo             pobj          to   noun                   1\n",
       "14          .            punct        want  punct                   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens:  14\n",
      "The Parse yields a tree.\n",
      "xcomp clause structure violated.\n",
      "No Lexical Repetitons Encountered\n",
      "Bigram repeated\n"
     ]
    }
   ],
   "source": [
    "# USAGE:\n",
    "print(\"Number of Tokens: \", len(extract))\n",
    "\n",
    "# Visualize the set of the extracted features\n",
    "display_features(extract)\n",
    "\n",
    "# if the resultant parse tree is connected or not\n",
    "temp = check_connected(extract)\n",
    "\n",
    "# if the resultant parse tree has any violations in xcomp structure\n",
    "temp = check_xcomp_conditions(extract)\n",
    "\n",
    "# get the tree-hash of the dependency tree\n",
    "temp = make_all_structs(extract)\n",
    "\n",
    "# check for lexical repetitions in 5 word windows\n",
    "result = check_repeat(extract)\n",
    "\n",
    "# check for repetitions of \"I\" in 5 word windows\n",
    "check = check_bi_repeat(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% Completed\n",
      "10% Completed\n",
      "15% Completed\n",
      "20% Completed\n",
      "25% Completed\n",
      "30% Completed\n",
      "35% Completed\n",
      "40% Completed\n",
      "45% Completed\n",
      "50% Completed\n",
      "55% Completed\n",
      "60% Completed\n",
      "65% Completed\n",
      "70% Completed\n",
      "75% Completed\n",
      "80% Completed\n",
      "85% Completed\n",
      "89% Completed\n",
      "94% Completed\n",
      "99% Completed\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Analysis:\n",
    "test_file_indices = [n for n in range(1, 5)]\n",
    "\n",
    "sentence_count = 0\n",
    "not_a_tree = 0\n",
    "xcomp_violated = 0\n",
    "repeated_count = 0\n",
    "repeated_count_parse = 0\n",
    "bi_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "invalid_repeated = 0\n",
    "invalid_repeated_parse = 0\n",
    "\n",
    "invalid_repeated_sentences = []\n",
    "invalid_repeated_parse_sentences = []\n",
    "\n",
    "for idx in test_file_indices:\n",
    "    sentences = test_files[idx]\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_count += 1\n",
    "        \n",
    "        if(sentence_count % 43 == 0):\n",
    "            print(str(round(sentence_count / 865 * 100)) + \"% Completed\")\n",
    "\n",
    "        extract_info = proc(sentence)\n",
    "\n",
    "        temp = make_all_structs(extract_info)\n",
    "        is_repetition_parse = check_repetitions(1)\n",
    "        \n",
    "        is_repetition_window = check_repeat(extract_info, 1)\n",
    "\n",
    "        is_bi_repeat = check_bi_repeat(extract_info, 1)\n",
    "        \n",
    "        flag_valid = 1\n",
    "        \n",
    "        if check_connected(extract_info, 1) == 0:\n",
    "            not_a_tree += 1\n",
    "            flag_valid = 0\n",
    "            \n",
    "        if check_xcomp_conditions(extract_info, 1) == 0:\n",
    "            xcomp_violated += 1\n",
    "            flag_valid = 0\n",
    "            \n",
    "        if flag_valid != 1:\n",
    "            invalid_count += 1\n",
    "        \n",
    "        repeated_count += is_repetition_window\n",
    "        repeated_count_parse += is_repetition_parse\n",
    "\n",
    "        bi_count += is_bi_repeat\n",
    "        \n",
    "        if flag_valid == 0 and is_repetition_window == 1:\n",
    "            invalid_repeated += 1\n",
    "            invalid_repeated_sentences.append(sentence)\n",
    "            \n",
    "        if flag_valid == 0 and is_repetition_parse == 1:\n",
    "            invalid_repeated_parse += 1\n",
    "            invalid_repeated_parse_sentences.append(sentence)\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Count</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not a Tree</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'xcomp' Condition Violated</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Possible Repetitions using Window</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Possible Repetitions using Parse</th>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigrams repeated</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parsing Constraint violated</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violation + Repetition with Window</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violation + Repetition with Parse</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Results\n",
       "Sentence Count                          865\n",
       "Not a Tree                               40\n",
       "'xcomp' Condition Violated                2\n",
       "Possible Repetitions using Window       253\n",
       "Possible Repetitions using Parse        627\n",
       "Bigrams repeated                          2\n",
       "Parsing Constraint violated              42\n",
       "Violation + Repetition with Window       18\n",
       "Violation + Repetition with Parse        30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the Results\n",
    "index_arr = ['Sentence Count', 'Not a Tree', '\\'xcomp\\' Condition Violated', 'Possible Repetitions using Window', 'Possible Repetitions using Parse',\n",
    "             'Bigrams repeated', 'Parsing Constraint violated', 'Violation + Repetition with Window', 'Violation + Repetition with Parse']\n",
    "results_arr = [sentence_count, not_a_tree, xcomp_violated, repeated_count, repeated_count_parse, bi_count,\n",
    "               invalid_count, invalid_repeated, invalid_repeated_parse]\n",
    "d_results = {\"Results\": results_arr}\n",
    "df_results = pd.DataFrame(index = index_arr, data = d_results)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Sentences violating parsing constraints: 4.86%\n",
      "Percentage of wrongly parsed Sentences showing Repetitions based on Parse: 71.43%\n",
      "Percentage of wrongly parsed Sentences showing Repetitions based on Window: 42.86%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of Sentences violating parsing constraints: \"\n",
    "      + str(round(invalid_count / sentence_count * 100, 2)) + '%')\n",
    "print(\"Percentage of wrongly parsed Sentences showing Repetitions based on Parse: \"\n",
    "      + str(round(invalid_repeated_parse / invalid_count * 100, 2)) + '%')\n",
    "print(\"Percentage of wrongly parsed Sentences showing Repetitions based on Window: \"\n",
    "      + str(round(invalid_repeated / invalid_count * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Sentences with Possibility of repetition using window:\n",
      "['Now , you can invoke free vortex law , either at the mean of the rotor blade or you may like to invoke it at the exit of the rotor blade , you can theoretically invoke it at the entry to the rotor blade , but normally it is not done , because the free vortex characteristic is acquired by the flow only when the flow goes to the rotor .', 'Now , this is of course , of value U , which you get from solid body relationship and that is the blade speed at that particular section U 1 r . Correspondingly , now you can find out the relative flow angle going into the blade and this of course , as we know , is found from the velocity triangle .', 'Now , the exit angle , flow angles can be also found using the whirl component and the axial components and the relative flow angle can also be found by using the blade velocity , the whirl component and the axial component by using the simple trigonometric relationship and if you do that , you would get the delta beta , which is the flow turning angle through the blade , that is , beta 2 minus beta 1 at the station r . Now , this is the delta beta that is all important value because this actually dominates or tells us , how much work is possible through this particular blades section .', 'You can indeed choose intermediate values , you do not have to choose only 0.5 or 1 or 2 , you can indeed choose intermediate values , but that well give you an idea , prima-facie a first cut idea based on two-dimensional cascade understanding how much delta beta , that particular blade section can actually produce .', 'Now , deviation is a parameter or deviation angle is a physical phenomenon , that happens due to the fact , that flow does not stick to the blade surface , it goes away from the blade surface when it is travelling on the blade surface , especially on the section surface , and the amount it rears away from the blade ’ s surface is known as deviation .', 'If you do that , you get value of m ; you put that value of m and you get corrected value of deviation or a corrected value of camber .', 'So , all the ones on the left hand side are subsonic blade sections , the ones on the right hand side are all transonic blade sections , then NACA 65 have sometimes early on were used for transonic , nowadays they are not used for transonic , rest of the blade section on right hand side are transonic blade sections .', 'We are not talking about twist at this moment , we are talking about some other geometrical parameters that bring in threedimensionality to the blade shape ; and in today ’ s lecture , we will be talking about threedimensional blade shapes .', 'You see , what happens is , the blade over here , see you have a flat tip , and then this flat tip needs to be , you know , covered with the casing , which is in variably , you know , curved casing ; and now , you have a situation , now this flat tip , we are looking at from a side , where this is staggered .', 'We have seen the blades are already twisted , we have seen blades already having varying camber from root to tip and we have seen they have differential stagger , substantially its different stager from root to tip .', 'So , this is the lean stacking line , over which the airfoils can be … So , this was the original stacking and then you have the airfoils now , leaned like this and these are the airfoils .', 'Acoustic power is defined as the Power Watt Level or PWL in some literature , in some books and this is given as 20 into log 10 W by W ref , and that is also in dB , and W is the acoustic power in watts , and W ref is the reference acoustic power in , that is normally given as 10 to power of minus 12 watts .', 'So , we have to keep an eye on that blade speed are the relative blade speed very stringently ; if you want to keep a check on the noise that is emanating from the rotating blades .', 'So , it can propagate in waves like this , it can keep on propagating or it can be somewhat decaying interaction field , where the noise , kind of , every particular noise source from B 1 S 1 , B 2 S 2 , kind of , sort of dies off ; they do not propagate along , as shown on top here and each of those interaction are die of on their own .', 'And , these are the noise regulations that have been put in place to safeguard the human beings that are present inside the aircraft or outside the aircraft in the airport ; which means that to confirm to regulation , the engine designer have to use noise containment or noise suppressing method , because , normally , some of the noise is indeed actually much higher than that .', 'So , most of the noise that is annoying to our ear is essentially high frequency noise and they need to be indeed attenuated or absorbed by certain mechanical means , so that , at least the minimum safety is guaranteed for the people who are around the aircraft .', 'Now , as we can see here , if we go by the drop , let us say the temperature drop of 03 to 04 prime , as we can see in this diagram very clearly , the 03 to 04 prime drop is indeed far higher than 03 to 04 drop , which is H 0T , which is the real work and H 03 prime is the ideal work .', 'And this curved passage produces this jet , high velocity jet , which is shown near C 2 and then , if it impinges at , and this rotor blade starts moving , it will have a motion .']\n",
      "Invalid Sentences with Possibility of repetition using parse:\n",
      "['Now , as a result of that , one can say that mean C w through this blade is C w 1 plus C w 2 divided by 2 and that is the mean C w operating on this rotor row ; on this rotor row , let us say , ok . Now , this if we say , that we are designing a blade with a free vortex law .', 'Now , you can invoke free vortex law , either at the mean of the rotor blade or you may like to invoke it at the exit of the rotor blade , you can theoretically invoke it at the entry to the rotor blade , but normally it is not done , because the free vortex characteristic is acquired by the flow only when the flow goes to the rotor .', 'Now , this is of course , of value U , which you get from solid body relationship and that is the blade speed at that particular section U 1 r . Correspondingly , now you can find out the relative flow angle going into the blade and this of course , as we know , is found from the velocity triangle .', 'Now , we know , that the degree of reaction should never be 0 anywhere on the blade or definitely , never be less than 0 anywhere on the rotor blade .', 'Now , the exit angle , flow angles can be also found using the whirl component and the axial components and the relative flow angle can also be found by using the blade velocity , the whirl component and the axial component by using the simple trigonometric relationship and if you do that , you would get the delta beta , which is the flow turning angle through the blade , that is , beta 2 minus beta 1 at the station r . Now , this is the delta beta that is all important value because this actually dominates or tells us , how much work is possible through this particular blades section .', 'The reason they are given a little on the negative at the tip is because we have seen earlier and we know , that the tip is the blade that is amenable to stall .', 'You can indeed choose intermediate values , you do not have to choose only 0.5 or 1 or 2 , you can indeed choose intermediate values , but that well give you an idea , prima-facie a first cut idea based on two-dimensional cascade understanding how much delta beta , that particular blade section can actually produce .', 'Now , deviation is a parameter or deviation angle is a physical phenomenon , that happens due to the fact , that flow does not stick to the blade surface , it goes away from the blade surface when it is travelling on the blade surface , especially on the section surface , and the amount it rears away from the blade ’ s surface is known as deviation .', 'Now , if we look at the deviation , the camber that we were talking about , it is the difference between the blade angles and it can be mentioned in terms of the delta beta , which is the flow turning angle , the incidence angle and then , the parameter m comes into picture multiplied by root over of inverse of solidity .', 'If you do that , you get value of m ; you put that value of m and you get corrected value of deviation or a corrected value of camber .', 'So , all the ones on the left hand side are subsonic blade sections , the ones on the right hand side are all transonic blade sections , then NACA 65 have sometimes early on were used for transonic , nowadays they are not used for transonic , rest of the blade section on right hand side are transonic blade sections .', 'I have given here the aerofoil coordinates of the 65 series blades , which are available in many literature also are easily available and so I have supplied it to you for your convenience .', 'You have the same steps that you have to do for rotor and then you do the same thing for the stator and only after you have done it for the stator , you have a stage .', 'So , we have gone through all the steps of the design and I have just tried to give you the simple steps that lead you towards first cut rotor and stator and stage design of an axial flow compressor .', 'So , these are some of the issues that are connected with standard or normal design procedure , which do produce in our reasonable good compressors ; but if you want to have more modern compressors , which are also reasonably efficient compressors , competitively efficient compressors , you probably need to look at beyond this standard aerofoil based , cascade based design procedure , and that is what we would try to indicate in today ’ s lecture .', 'Now , if you have a flat tip , that is stagger , and then you have a casing , which is a covering , shrove ; that is , invariably they are in compressors , the gap between the rotor and the casing from leading edge to trailing edge , then becomes a problem .', 'You see , what happens is , the blade over here , see you have a flat tip , and then this flat tip needs to be , you know , covered with the casing , which is in variably , you know , curved casing ; and now , you have a situation , now this flat tip , we are looking at from a side , where this is staggered .', 'So , this is the lean stacking line , over which the airfoils can be … So , this was the original stacking and then you have the airfoils now , leaned like this and these are the airfoils .', 'And , it is one of the reasons , in fact one of the main reasons , why commercial aircrafts compressors and fans , fans being the first component in the compressor , have not gone beyond the transonic or let us say , middle transonic Mach numbers , where the tip relative Mach numbers is of the order of 1.5 or 1.6 The military engines have gone beyond that , so the technology for making high Mach number fans and compressors do exits , but they are not being used in commercial aircraft engines and one of the main reasons is noise .', 'Acoustic power is defined as the Power Watt Level or PWL in some literature , in some books and this is given as 20 into log 10 W by W ref , and that is also in dB , and W is the acoustic power in watts , and W ref is the reference acoustic power in , that is normally given as 10 to power of minus 12 watts .', 'So , it can propagate in waves like this , it can keep on propagating or it can be somewhat decaying interaction field , where the noise , kind of , every particular noise source from B 1 S 1 , B 2 S 2 , kind of , sort of dies off ; they do not propagate along , as shown on top here and each of those interaction are die of on their own .', 'And , these are the noise regulations that have been put in place to safeguard the human beings that are present inside the aircraft or outside the aircraft in the airport ; which means that to confirm to regulation , the engine designer have to use noise containment or noise suppressing method , because , normally , some of the noise is indeed actually much higher than that .', 'Now , which , as we know , in case of axial flow compressor , it does not quite fully go axial , it kind of zig-zags through the blades ; in case of axial flow turbines , that zig-zaging is actually even more .', 'Now , let us take a look at what are the various issues related to the turbine that we would need to really get in to ; because , what we need to get in to is the aerodynamics or the gas dynamics turbine and we need to get into the fact that it has being a part of a heat engine , you know , we are talking about heat engine and a turbine is very much component of a heat engine , a major , probably the fundamental comp 1nt of heat engine that we are talking about , and as a result of which , it has to satisfy or confirm to very closely as closely and accurately as possible to many of the laws of thermodynamics .', 'Now , as we can see here , if we go by the drop , let us say the temperature drop of 03 to 04 prime , as we can see in this diagram very clearly , the 03 to 04 prime drop is indeed far higher than 03 to 04 drop , which is H 0T , which is the real work and H 03 prime is the ideal work .', 'Also , as we see here , the real dynamic head at the exit is C 4 square , the ideal dynamic head is C 4 prime square ; for the sake of certain amount of simplification , quite often it is assumed that these two values of C 4 , that is , C 4 prime ideal and C 4 , that is ideal , are equal to each other ; which means , difference between P 4 prime to 04 prime and 4 to 0 4 are equal to each other ; that is for simplification for many thermodynamic analysis .', 'And this curved passage produces this jet , high velocity jet , which is shown near C 2 and then , if it impinges at , and this rotor blade starts moving , it will have a motion .', 'And then , the rotor blades give out the velocity V 3 , which is relative to the moving blade ; and then , if you subtract the motion of the blade itself , U again , you are , you get the residual ; that is C 3 , which is the exit velocity of the flow coming out of this turbine stage .', 'These details would be done , you know , again and again , starting with the next lecture and you get to use this more and more , as we ago long in this lecture series .', 'So , in this diagram , it simply means that V 3 more than V 2 would be a reaction turbine ; if there equal , it is an impulse turbine .']\n"
     ]
    }
   ],
   "source": [
    "# Visualizing results qualitatively\n",
    "\n",
    "print(\"Invalid Sentences with Possibility of repetition using window:\")\n",
    "print(invalid_repeated_sentences)\n",
    "\n",
    "print(\"Invalid Sentences with Possibility of repetition using parse:\")\n",
    "print(invalid_repeated_parse_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's All Folks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
